# Satellite Image Segmentation and Analysis Workflow for Flood Mapping (UFO Dataset)

This repository contains the code for a workflow developed for semantic segmentation of satellite imagery, specifically focused on water detection in the context of urban flood mapping. The workflow utilizes deep learning (U-Net architecture with `fastai`), includes training with Leave-One-Event-Out cross-validation, prediction, mosaicking, and quantitative evaluation, along with scripts and a notebook for generating figures and analyzing results.

This code is a companion to the research paper:
**Urban Flood Observations (UFO): A hand-labeled training and validation dataset of post-flood inundation**
*Rohit Mukherjee, Hannah K. Friedrich, Beth Tellman, Ariful Islam, Zhijie Zhang, Jonathan Giezendanner, Upmanu Lall, and Venkataraman Lakshmi*

**Note:** The code contains hardcoded file paths that **must** be updated to match your local setup after downloading and extracting the dataset.

## Dataset

The Urban Flood Observation (UFO) dataset, a global, high-resolution, hand-labeled collection of post-flood inundation imagery in diverse urban settings, is publicly available on Zenodo:

**Dataset Link:** [https://zenodo.org/records/15238470](https://zenodo.org/records/15238470)

Please download and extract the dataset. The codebase is configured to expect a specific directory structure derived from the extracted data, particularly for the input images and ground truth labels used for training and validation. Based on the code paths and the paper's description, the expected structure within your designated data directory should resemble:

/path/to/your/data/
└── trainingDatasetUFO0129_256/
    ├── images0207_localNorm_256_GroupedByEvents/
    │   ├── BEI/
    │   │   └── image_files.tif
    │   ├── BNA/
    │   │   └── image_files.tif
    │   ├── CMO/
    │   │   └── image_files.tif
    │   ├── CTO/
    │   │   └── image_files.tif
    │   ├── DKA/
    │   │   └── image_files.tif
    │   └── …  (one sub-folder per SiteID, total 14 events)
    │
    ├── labels0129_256_GroupedByEvents/
    │   ├── BEI/
    │   │   └── label_files.tif     ← masks (1 = inundated, 0 = non-inundated)
    │   ├── BNA/
    │   │   └── label_files.tif
    │   ├── CMO/
    │   │   └── label_files.tif
    │   ├── CTO/
    │   │   └── label_files.tif
    │   ├── DKA/
    │   │   └── label_files.tif
    │   └── …  (matching the 14 event folders above)
    │
    └── other/                     ← optional extra files/folders
        ├── STAC_catalog.json     ← e.g. STAC catalog from extraction
        └── README.md             ← any additional documentation


Additionally, some scripts or notebook cells might require specific CSV files generated by the evaluation steps or the GeoJSON file containing event locations mentioned in the paper. Ensure these are accessible and their paths are updated accordingly.

## Installation

1.  **Clone the repository:**
    ```bash
    git clone <repository_url>
    cd <repository_name>
    ```
2.  **Install dependencies:** It is highly recommended to use a virtual environment (`conda` or `venv`). The required libraries are listed in the paper's Code Availability section and inferred from the code imports.
    ```bash
    pip install pandas numpy torch torchvision torchaudio fastai rasterio scikit-image scikit-learn seaborn matplotlib geopandas cartopy squarify
    ```
    *Note: GPU acceleration is essential for timely training of the deep learning model with PyTorch/fastai.*

## Code Structure and Usage

The repository is organized into key scripts and a Jupyter Notebook to execute the workflow and generate analysis figures:

1.  **`oneSinglePipeline.py`:**
    *   **Purpose:** Executes the full end-to-end workflow: **training → inference → mosaicking → evaluation**.
    *   **Functionality:** Implements the Leave-One-Event-Out cross-validation strategy. It iteratively trains a U-Net model on 13 flood events, uses the trained model to predict inundation for the held-out event, saves the predictions (georeferenced GeoTIFFs), mosaics the predicted tiles for each event, and calculates standard segmentation metrics (IoU, Precision, Sensitivity, Specificity, F1, Accuracy) by comparing predictions against ground truth labels, saving results to a CSV file.
    *   **Usage:**
        1.  Download and extract the dataset (see [Dataset](#dataset) section).
        2.  **Crucially, update all hardcoded file paths** defined at the beginning of `oneSinglePipeline.py` (e.g., `base_path`, `input_base_path`, `labels_base_path`, `log_file`, `model_load_path`, `output_folder`, `output_base`, `pred_folder`, `val_folder`, `csv_output_path`) to match your data locations.
        3.  Run the script from your terminal:
            ```bash
            python oneSinglePipeline.py
            ```
    *   **Outputs:** Trained models (saved per LOEO fold), tiled predictions (GeoTIFFs), mosaicked predictions (GeoTIFFs in the `output_base` directory), and an evaluation results CSV file (`csv_output_path`).

2.  **`validateUFO.py`:**
    *   **Purpose:** Performs a stand-alone evaluation on existing prediction GeoTIFFs.
    *   **Functionality:** Reads a directory of predicted inundation masks and a corresponding directory of ground truth labels. It calculates per-file confusion matrices and standard segmentation metrics. This script can be used to evaluate prediction sets generated by `oneSinglePipeline.py` or other methods, saving the results to a CSV file.
    *   **Usage:**
        1.  Ensure you have predicted masks and ground truth labels in accessible directories (e.g., the outputs from `oneSinglePipeline.py`).
        2.  Update the input (`pred_folder`, `val_folder`) and output (`csv_output_path`) paths in the script.
        3.  Run the script:
            ```bash
            python validateUFO.py
            ```
    *   **Outputs:** An evaluation results CSV file containing metrics for each evaluated file/region, typically including an 'overall_mean'.

3.  **`plotValResultsUFO.py`:**
    *   **Purpose:** Generates summary plots from the evaluation results CSV created by `oneSinglePipeline.py` or `validateUFO.py`.
    *   **Functionality:** Reads a specific evaluation CSV file (likely the one named `perLabelSpec.csv` in the code snippets). It calculates mean specificity per region, normalizes it for color-coding, and generates a boxplot showing the distribution of Specificity per region, overlaid with individual data points and using a colorbar to represent mean specificity. This corresponds to Figure 7 in the paper.
    *   **Usage:**
        1.  Ensure you have the evaluation results CSV file (e.g., `perLabelSpec.csv`).
        2.  Update the input CSV file path (`data_path`) and the output path (`output_filename`) in the script.
        3.  Run the script:
            ```bash
            python plotValResultsUFO.py
            ```
    *   **Outputs:** Displays the generated matplotlib/seaborn plot and saves it as a PDF file.

4.  **`UFO_figures.ipynb`:**
    *   **Purpose:** A Jupyter Notebook containing code to reproduce figures similar to those presented in the research manuscript.
    *   **Functionality:** This notebook likely loads various data sources, including raw data characteristics (like from the initial data frame snippet showing event counts, flooded %, permanent water %), evaluation CSVs from different models/sources (potentially those comparing PS-based vs. Sentinel-based, PS-based vs. Dynamic World), and potentially the GeoJSON event locations. It contains code cells to generate plots such as map visualizations (Figure 1), bubble plots (Figure 2, though the provided snippet shows a bar plot), boxplots comparing metrics across different sources/models (Figure 10), and potentially dumbbell plots or plots showing metric differences.
    *   **Usage:**
        1.  Ensure you have completed the `oneSinglePipeline.py` run to generate necessary outputs (mosaicked predictions, evaluation CSVs like `..._Preds.csv`, `normalized_iou_per_region.csv`, potentially comparison CSVs like `predictionsPSS1.csv`, `predictionsPSDW.csv`).
        2.  Ensure you have the GeoJSON file (`UFOEventsCentroids.geojson`) if required for map figures.
        3.  Update all relevant data paths within the notebook cells.
        4.  Open the notebook in a Jupyter environment (e.g., JupyterLab, VS Code, Google Colab) with the project dependencies installed and access to the data.
        5.  Run the code cells sequentially to regenerate the figures.
    *   **Outputs:** Displays generated figures within the notebook cells. Notebook cells also include commands to save figures to PDF files.

## Features

*   **Deep Learning Segmentation:** U-Net models based on `resnet50`/`resnet34` encoders.
*   **Leave-One-Event-Out Cross-Validation:** Robust training and evaluation method applied per flood event.
*   **Custom Data Handling:** Supports multi-channel GeoTIFF input images and masks using tailored `fastai` components.
*   **Custom Loss Function:** Employs a `CombinedLoss` (Focal + Dice) for improved segmentation performance, especially with class imbalance.
*   **Georeferenced Predictions:** Saves predictions preserving spatial metadata using `rasterio`.
*   **Prediction Mosaicking:** Stitches predicted tiles into event/region-level mosaics using `rasterio.merge`.
*   **Quantitative Evaluation:** Calculates standard metrics (Precision, Sensitivity, Specificity, F1, IoU, Accuracy) using `sklearn.metrics` and confusion matrices.
*   **Data Analysis and Visualization:** Comprehensive plotting capabilities using `pandas`, `seaborn`, `matplotlib`, `geopandas`, and `cartopy` to visualize data characteristics, model performance distributions, comparisons between methods, and spatial aspects.

## Dependencies

The core dependencies are:

*   `Python` (version compatible with libraries, likely 3.7+)
*   `pandas`
*   `numpy`
*   `torch`
*   `fastai`
*   `rasterio` (and its dependencies)
*   `scikit-image`
*   `scikit-learn`
*   `seaborn`
*   `matplotlib`
*   `geopandas`
*   `cartopy`
*   `squarify`

Ensure you have these installed before running the code.

## License

Creative Commons Attribution 4.0 International

## Acknowledgements

This project utilizes the `fastai` deep learning library, `PyTorch`, `rasterio` for spatial data handling, and `pandas`, `seaborn`, and `matplotlib` for data analysis and visualization. `geopandas` and `cartopy` are used for geospatial plotting. The project is based on the Urban Flood Observation (UFO) dataset.

This work was supported by a NASA Terrestrial Hydrology Program grant (#80NSSC21K1044), as mentioned in the paper. We acknowledge the assistance with labeling from Simone Holliday, Patrick Hellmann, Natasha Rapp, and Linn Ji, and the contributions of all co-authors listed in the paper.
